{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics of Song Lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_1.txt\").read()\n",
    "d2 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_2.txt\").read()\n",
    "d3 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_3.txt\").read()\n",
    "d4 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_4.txt\").read()\n",
    "d5 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_5.txt\").read()\n",
    "d6 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_6.txt\").read()\n",
    "d7 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_7.txt\").read()\n",
    "d8 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_8.txt\").read()\n",
    "d9 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_9.txt\").read()\n",
    "d10 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_10.txt\").read()\n",
    "d11 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_1.txt\").read()\n",
    "d12 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_2.txt\").read()\n",
    "d13 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_3.txt\").read()\n",
    "d14 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_4.txt\").read()\n",
    "d15 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_5.txt\").read()\n",
    "d16 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_6.txt\").read()\n",
    "d17 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_7.txt\").read()\n",
    "d18 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_8.txt\").read()\n",
    "d19 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_9.txt\").read()\n",
    "d20 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_10.txt\").read()\n",
    "d21 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_2.txt\").read()\n",
    "d22 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_3.txt\").read()\n",
    "d23 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_4.txt\").read()\n",
    "d24 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_5.txt\").read()\n",
    "d25 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_6.txt\").read()\n",
    "d26 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_7.txt\").read()\n",
    "d27 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_8.txt\").read()\n",
    "d28 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_9.txt\").read()\n",
    "d29 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_10.txt\").read()\n",
    "d30 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_2.txt\").read()\n",
    "d31 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_3.txt\").read()\n",
    "d32 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_4.txt\").read()\n",
    "d33 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_5.txt\").read()\n",
    "d34 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_6.txt\").read()\n",
    "d35 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_7.txt\").read()\n",
    "d36 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_8.txt\").read()\n",
    "d37 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_9.txt\").read()\n",
    "d38 = open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/tfidf_10.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23,d24,d25,d26,d27,d28,d29,d30,d31,d32,d33,d34,d35,d36,d37,d38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 1000\n",
    "n_topics = 20\n",
    "n_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, max_features=n_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "yeah wanna somebody look oh\n",
      "\n",
      "\n",
      "Topic #1:\n",
      "best like love chance rapper\n",
      "\n",
      "\n",
      "Topic #2:\n",
      "sure traveled blessed soul days\n",
      "\n",
      "\n",
      "Topic #3:\n",
      "warm love keeps wanted tried\n",
      "\n",
      "\n",
      "Topic #4:\n",
      "house bring ll place draggin\n",
      "\n",
      "\n",
      "Topic #5:\n",
      "things baby oh real hard\n",
      "\n",
      "\n",
      "Topic #6:\n",
      "chorus head cause oh imperfections\n",
      "\n",
      "\n",
      "Topic #7:\n",
      "chorus like hollow verse kill\n",
      "\n",
      "\n",
      "Topic #8:\n",
      "marry wanna baby oh think\n",
      "\n",
      "\n",
      "Topic #9:\n",
      "lights kiss turn baby darkest\n",
      "\n",
      "\n",
      "Topic #10:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #11:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #12:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #13:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #14:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #15:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #16:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #17:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #18:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n",
      "Topic #19:\n",
      "zombie dreams forgot fortune foxy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2x',\n",
       " u'3x',\n",
       " u'400',\n",
       " u'act',\n",
       " u'aid',\n",
       " u'ain',\n",
       " u'alright',\n",
       " u'antelope',\n",
       " u'apart',\n",
       " u'arkansas',\n",
       " u'ask',\n",
       " u'ass',\n",
       " u'asscrack',\n",
       " u'away',\n",
       " u'baby',\n",
       " u'backseat',\n",
       " u'bake',\n",
       " u'bath',\n",
       " u'beating',\n",
       " u'beautiful',\n",
       " u'bedroom',\n",
       " u'beginning',\n",
       " u'believe',\n",
       " u'bells',\n",
       " u'best',\n",
       " u'better',\n",
       " u'beverage',\n",
       " u'big',\n",
       " u'billionaire',\n",
       " u'bird',\n",
       " u'blame',\n",
       " u'blessed',\n",
       " u'blow',\n",
       " u'blue',\n",
       " u'blues',\n",
       " u'bosom',\n",
       " u'bottles',\n",
       " u'boulevard',\n",
       " u'bout',\n",
       " u'boy',\n",
       " u'brave',\n",
       " u'bread',\n",
       " u'break',\n",
       " u'breasts',\n",
       " u'breathing',\n",
       " u'bride',\n",
       " u'bridge',\n",
       " u'bright',\n",
       " u'bring',\n",
       " u'broccoli',\n",
       " u'brought',\n",
       " u'brown',\n",
       " u'buffalo',\n",
       " u'butler',\n",
       " u'buy',\n",
       " u'buyin',\n",
       " u'called',\n",
       " u'car',\n",
       " u'cards',\n",
       " u'care',\n",
       " u'carefully',\n",
       " u'cares',\n",
       " u'cash',\n",
       " u'cast',\n",
       " u'caught',\n",
       " u'cause',\n",
       " u'chance',\n",
       " u'change',\n",
       " u'chapel',\n",
       " u'chef',\n",
       " u'chi',\n",
       " u'chocolate',\n",
       " u'choir',\n",
       " u'chorus',\n",
       " u'clean',\n",
       " u'cleaning',\n",
       " u'clock',\n",
       " u'clouds',\n",
       " u'coffee',\n",
       " u'come',\n",
       " u'comes',\n",
       " u'coming',\n",
       " u'controller',\n",
       " u'cool',\n",
       " u'count',\n",
       " u'counting',\n",
       " u'county',\n",
       " u'cousins',\n",
       " u'crashing',\n",
       " u'crazy',\n",
       " u'crossed',\n",
       " u'crowd',\n",
       " u'crying',\n",
       " u'curtain',\n",
       " u'curves',\n",
       " u'cuz',\n",
       " u'd5',\n",
       " u'dancing',\n",
       " u'darkest',\n",
       " u'darling',\n",
       " u'dart',\n",
       " u'dash',\n",
       " u'day',\n",
       " u'daylight',\n",
       " u'days',\n",
       " u'dead',\n",
       " u'deal',\n",
       " u'dedication',\n",
       " u'dee',\n",
       " u'demi',\n",
       " u'deuce',\n",
       " u'diamond',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'distraction',\n",
       " u'dizzy',\n",
       " u'dj',\n",
       " u'does',\n",
       " u'don',\n",
       " u'doooooo',\n",
       " u'door',\n",
       " u'downfall',\n",
       " u'dozen',\n",
       " u'draggin',\n",
       " u'drain',\n",
       " u'drama',\n",
       " u'drape',\n",
       " u'drawing',\n",
       " u'dreams',\n",
       " u'dress',\n",
       " u'dressed',\n",
       " u'drive',\n",
       " u'dumb',\n",
       " u'easily',\n",
       " u'eat',\n",
       " u'edges',\n",
       " u'electric',\n",
       " u'em',\n",
       " u'end',\n",
       " u'engine',\n",
       " u'everybody',\n",
       " u'eye',\n",
       " u'eyes',\n",
       " u'face',\n",
       " u'fall',\n",
       " u'falling',\n",
       " u'falls',\n",
       " u'favorite',\n",
       " u'feat',\n",
       " u'feel',\n",
       " u'feeling',\n",
       " u'feet',\n",
       " u'figure',\n",
       " u'finally',\n",
       " u'fine',\n",
       " u'fingers',\n",
       " u'flashbacks',\n",
       " u'flew',\n",
       " u'flickin',\n",
       " u'flight',\n",
       " u'flying',\n",
       " u'forever',\n",
       " u'forgot',\n",
       " u'fortune']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative=[]\n",
    "with open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/words_negative.csv\", \"rb\") as file:\n",
    "    reader=csv.reader(file)\n",
    "    for row in reader:\n",
    "        negative.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive=[]\n",
    "with open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/words_positive.csv\", \"rb\") as file:\n",
    "    reader=csv.reader(file)\n",
    "    for row in reader:\n",
    "        positive.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2x',\n",
       " u'3x',\n",
       " u'400',\n",
       " u'act',\n",
       " u'aid',\n",
       " u'ain',\n",
       " u'alright',\n",
       " u'antelope',\n",
       " u'apart',\n",
       " u'arkansas']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Volumes/BATMAN/Natural Language Processing/Introduction-to-NLP-master/5. Projects/words.csv\", 'wb') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "n_count=0\n",
    "p_count=0\n",
    "for word in feature_names:\n",
    "    for item in positive:\n",
    "        if(word == item[0]):\n",
    "                    p_count +=1\n",
    "    for item in negative:\n",
    "        if(word == item[0]):\n",
    "                    n_count +=1\n",
    "    if(p_count > 0 and n_count == 0):\n",
    "            temp.append(1)\n",
    "    elif(n_count%2 > 0):\n",
    "            temp.append(-1)\n",
    "    elif(n_count%2 == 0 and n_count > 0):\n",
    "            temp.append(+1)\n",
    "    else:\n",
    "            temp.append(0)\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.250972762646\n"
     ]
    }
   ],
   "source": [
    "print np.average(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}